# Campos obrigatórios (Modelos do evaluation)
run_id: "my_run"
backend: "vllm"
model_paths:
  # - path: "meta-llama/Llama-3.2-3B-Instruct"
  #   custom: false
  #   tokenizer_path: "meta-llama/Llama-3.2-3B-Instruct"
  - path: "Qwen/Qwen3-4B-Instruct-2507"
    custom: false
    tokenizer_path: "Qwen/Qwen3-4B-Instruct-2507"
    model_type: "instruct"
  # - path: "Qwen/Qwen3-4B-Base"
  #   custom: false
  #   tokenizer_path: "Qwen/Qwen3-4B-Base"
  #   model_type: "base"
  # - path: "gemini-2.5-flash-lite"
  #   custom: false
  #   tokenizer_path: "api"
  #   model_type: "instruct"

# Campos opcionais (Parâmetros do script)
multi_gpu:
  enabled: true
  num_gpus: 4
  mode: "data"

run_local: true
flash_attention: false
update_leaderboard: false
num_shots: 0
num_experiments: 1
benchmark_names:
  # - "assin2rte"
  # - "assin2sts"
  # - "bluex"
  # - "enem"
  # - "hatebr"
  # - "portuguese_hate_speech"
  # - "toxsyn_pt"
  # - "faquad"
  # - "tweetsentbr"
  # - "oab"
  # - "poscomp"
  # - "energy_regulacao"
  - "aime24"
  - "aime25"
  - "mmlu"
  - "mmlu_en"
  - "mmlu_hard"
  - "mmlu_redux_en"
  - "mmlu_pro_en"
  # - "supergpqa"
  # - "supergpqa_en"
  # - "include"
  - "mmmlu"

use_outlines: false
max_new_tokens: 4096
batch_size: 128
use_percentage_dataset: 10